{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORTING THE LIBRARIES AND MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local modules\n",
    "import model_helper\n",
    "import preprocess\n",
    "import helper\n",
    "\n",
    "# external libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOADING THE DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_telecom_customer_data(filename):\n",
    "    if os.path.isfile(filename):\n",
    "      return pd.read_csv(filename)\n",
    "    else:\n",
    "      return (\"Invalid file name, make sure the filename is correct and is in the same package\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TelecomCustomerData = load_telecom_customer_data('TelcoCustomerChurn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TelecomCustomerData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TelecomCustomerData.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXPLORE AND VISUALISE THE DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TelecomCustomerData.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_copy, validate_copy, test_copy = preprocess.process_unencoded_data(data=TelecomCustomerData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(train_copy, hue='Churn')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='Churn', y='MonthlyCharges', data=train_copy, color='lightblue')\n",
    "plt.title(\"Comparing monthly charges of customers that churn and those that do not churn\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='TotalCharges', y='Churn', data=train_copy, color='green')\n",
    "plt.title(\"Comparing Total charges of customers that churn and those that do not churn\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxenplot(data=train_copy,x='Churn',y='TotalCharges' )\n",
    "plt.title(\"Comparing Total charges of customers that churn and those that do not churn\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxenplot(data=train_copy, x='Churn', y='MonthlyCharges')\n",
    "plt.title(\"Comparing monthly charges of customers that churn and those that do not churn\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PREPROCESS THE DATA\n",
    "Here, I used the function process_unencoded_data in the preprocess file to split data into train, validate, and testing data.\n",
    "Afterwards, I clean the data and prepared it for training, validating and testing by performing the following operations;\n",
    "* Stripped all leading and trailing whitespaces from each categorical column.\n",
    "* Dropped rows where tenure was zero.\n",
    "* Transformed 'TotalCharges' from object data type to float data type.\n",
    "* Dropped duplicates.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here I am going to use the functions defined in the preprocess.py file to prepare the data for training, validating and testin\n",
    "train_data, validate_data, test_data = preprocess.process_clean_data(data=TelecomCustomerData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the control model score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the training dataset x and y variables for trianing\n",
    "x_train_data, y_train_data = train_data.drop('Churn', axis=1), train_data.Churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the validating dataset into x and y variables for validating\n",
    "x_validate_data, y_validate_data = validate_data.drop('Churn', axis = 1), validate_data.Churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the testing dataset into x and y variables for testing\n",
    "x_test_data, y_test_data = test_data.drop('Churn', axis = 1), test_data.Churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy for the control model is:  73.43 %\n"
     ]
    }
   ],
   "source": [
    "# Getting the control model score as the baseline using the get_control_score function in the model_helper.py file\n",
    "# I used the DummyClassifier model in the sklearn library for this\n",
    "score = model_helper.get_control_score(x_train_data, y_train_data)\n",
    "print(\"The accuracy for the control model is: \", (score*100).round(2), '%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAINING AND COMPARING MODELS\n",
    "\n",
    "* Here I train models using the Random Forest algorithm from the sklearn library.\n",
    "* The main procedures and computations have been delegated to the functions in the model_helper.py module\n",
    "* I will be using these functions to train and compare different models with the Random Forest classifier by using different random_state, max_depth and min_samples_leaf for each model\n",
    "#### NB: More details in the doctstrings of each function in the model_helper module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_classifiers = model_helper.compare_models(x_train = x_train_data,y_train= y_train_data, x_validate = x_validate_data,y_validate = y_validate_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_classifiers[random_forest_classifiers['Validate Score'] > 0.80]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TESTING AND EVALUATING THE CLASSIFIER WITH THE BEST FEATURE SECLECTION  \n",
    "\n",
    "* Here I mak predictions with the classifier model that appears to perform better after evaluating a number of models with the random forest classifier.\n",
    "* None of the models from the results of the cell above (using different values used for max_depth, and min_samples_leaf in evalating the models ) were grealty over fit\n",
    "* Now, after the evaluation, the model with min_samples_leaf = 5 and max_depth appears to have the best performance sine it has the best recal score and the slightly higher accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>True Positves</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>True Negatives</th>\n",
       "      <th>False Negatvies</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Training Score</th>\n",
       "      <th>Validate Score</th>\n",
       "      <th>Test Score</th>\n",
       "      <th>Score Difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>171</td>\n",
       "      <td>94</td>\n",
       "      <td>939</td>\n",
       "      <td>203</td>\n",
       "      <td>0.645283</td>\n",
       "      <td>0.457219</td>\n",
       "      <td>0.837948</td>\n",
       "      <td>0.812796</td>\n",
       "      <td>0.788913</td>\n",
       "      <td>0.023884</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   max_depth  min_samples_leaf  True Positves  False Positives  \\\n",
       "0         10                 5            171               94   \n",
       "\n",
       "   True Negatives  False Negatvies  Precision    Recall  Training Score  \\\n",
       "0             939              203   0.645283  0.457219        0.837948   \n",
       "\n",
       "   Validate Score  Test Score  Score Difference  \n",
       "0        0.812796    0.788913          0.023884  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now selecting and testing the chosen model.\n",
    "from test_predict import test_classifier\n",
    "model, dataframe = test_classifier(x_train_data, y_train_data,x_validate_data,y_validate_data, x_test_data,y_test_data)\n",
    "\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from test_predict import compute_predictions_dataframe   \n",
    "# (explore_data, classifier, X_test):\n",
    "predict_dataframe = compute_predictions_dataframe(test_copy, model, x_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from test_predict import write_to_csv\n",
    "write_to_csv(predict_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('myenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9930ed311909a79bf496311ac9bdcd4a6f8e1da00149b644953bc490107a5c12"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
